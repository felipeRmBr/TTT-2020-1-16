{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVC - FULL DATASET CLASSIFIERS.ipynb","provenance":[],"collapsed_sections":["CcibWdBQd_9V","CK6vK73regWJ"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RfekjF9mkdWy"},"source":["# Ajustes iniciales"]},{"cell_type":"markdown","metadata":{"id":"zgdSkhxZdv0_"},"source":["## Conexión a google drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rEA8wkz2HzN","executionInfo":{"status":"ok","timestamp":1622872423984,"user_tz":300,"elapsed":144369,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"540cc30f-406e-4668-995c-d7833e5e7f8d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Crq_ww9d2GNh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622872439754,"user_tz":300,"elapsed":173,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"be132979-be6d-45e9-fb71-50d2ea8700c0"},"source":["%cd ./drive/MyDrive/Colab Notebooks/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"PwoDWvGgk8oT","executionInfo":{"status":"ok","timestamp":1622872440013,"user_tz":300,"elapsed":29,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"42495f4a-4117-4cc6-d3fd-e035e5477319"},"source":["%pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"qDN_7IBkXjrl"},"source":["## Instalar microTC"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRhkanwGXjrw","executionInfo":{"status":"ok","timestamp":1622606490612,"user_tz":300,"elapsed":6318,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"b8a40688-39b7-4fb0-ac02-4b36cab87b9f"},"source":["%pip install git+https://github.com/felipeRmBr/microtc.git#egg=microtc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting microtc\n","  Cloning https://github.com/felipeRmBr/microtc.git to /tmp/pip-install-63242k11/microtc\n","  Running command git clone -q https://github.com/felipeRmBr/microtc.git /tmp/pip-install-63242k11/microtc\n","Building wheels for collected packages: microtc\n","  Building wheel for microtc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for microtc: filename=microtc-2.2.8-cp37-none-any.whl size=60798 sha256=3d7efb0e339b46d928c0146fec48f92b9fd8a799cbe6c5a8d513880f715866a2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4ch3860s/wheels/73/00/4e/a4e2fc519599a41145f1740a75c80f390d4bcef72fed066f56\n","Successfully built microtc\n","Installing collected packages: microtc\n","Successfully installed microtc-2.2.8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8fz70fVKJJ11"},"source":["## Importar modulos *_utils\n"]},{"cell_type":"code","metadata":{"id":"Vm7v_xFpU3sr"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n","from my_utils import dataset_utils\n","from my_utils import eval_utils\n","from my_utils import svc_utils #(depends on microtc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jcdhuxpmcmbw"},"source":["import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WlIhN-PAc7Z1"},"source":["## Modelos de predefinidos"]},{"cell_type":"code","metadata":{"id":"9bSBLpSiekuP"},"source":["from microtc.textmodel import TextModel\n","\n","predefined_TM = []\n","\n","token_list_options = [[-3, -1, 3, 7],\n","                      [-3, -2, -1, 3, 6],\n","                      [-1, 3, 7],\n","                      [-3, -2, -1, 3, 7],\n","                      [-2, -1, 3, 7]]\n","\n","for token_list in token_list_options:\n","  text_model = TextModel(num_option='group',\n","                        usr_option='delete',\n","                        url_option='delete',\n","                        hashtag_option='delete', \n","                        emo_option='none',\n","                        del_punc=True,\n","                        del_dup=False,\n","                        del_diac=True,\n","                        token_list=token_list,\n","                        weighting='tfidf')\n","  \n","  predefined_TM.append(text_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EuWlJy4y8fnh"},"source":["from microtc.textmodel import TextModel\n","\n","predefined_TM = []\n","\n","token_list_options = [[-2,-1,3],\n","                      [-2,-1,3,4],\n","                      [-3, -1, 3, 7]]\n","\n","for token_list in token_list_options:\n","  text_model = TextModel(num_option='group',\n","                        usr_option='group',\n","                        url_option='group',\n","                        hashtag_option='group', \n","                        emo_option='none',\n","                        del_dup=True,\n","                        del_diac=True,\n","                        token_list=token_list,\n","                        weighting='tfidf')\n","  \n","  predefined_TM.append(text_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4tehk1arB4q2"},"source":["from microtc.textmodel import TextModel\n","\n","predefined_text_models = []\n","\n","token_list_options = [[-1,3],\n","                      [-2,-1,3],\n","                      [-3,-1,3],\n","                      [-1,3,4]]\n","\n","for token_list in token_list_options:\n","  text_model = TextModel(num_option='group',\n","                        usr_option='group',\n","                        url_option='group',\n","                        hashtag_option='group', \n","                        emo_option='none',\n","                        del_dup=False,\n","                        del_diac=True,\n","                        token_list=token_list,\n","                        weighting='tfidf')\n","  \n","  predefined_text_models.append(text_model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_R9NYVMFYlkz","executionInfo":{"status":"ok","timestamp":1618554554976,"user_tz":300,"elapsed":8563,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"8ecb5c14-38cb-4272-e602-449ed0ba0a41"},"source":["predefined_text_models"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<microtc.textmodel.TextModel at 0x7f0144413b10>,\n"," <microtc.textmodel.TextModel at 0x7f0144413190>,\n"," <microtc.textmodel.TextModel at 0x7f01444132d0>,\n"," <microtc.textmodel.TextModel at 0x7f0144413050>]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"RNJSRKzpPmL9"},"source":["# Train Global classifiers"]},{"cell_type":"markdown","metadata":{"id":"F20G39syVLSh"},"source":["## HS - linear kernel"]},{"cell_type":"code","metadata":{"id":"JXqvHqMBXjYH"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['HS'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJuAC1LVXjYJ"},"source":["configurations_ids = ['GQZgqx', 'hwmIFg', 'tgCmGg', 'fwZpdd', 'wavzCG']\n","textmodels_ids = ['CgOJHi', 'bVkhBU', 'wxNaSh', 'WHTRQA', 'iTLnGg']\n","\n","# HS linear kernel\n","tm_settings_list = [ ['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 7], 'tfidf'],\n","['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 7], 'tfidf'],\n","['group', 'delete', 'group', 'delete', True, False, True, [-2, -1, 3, 5, 7], 'tfidf'],\n","['group', 'delete', 'delete', 'delete', True, False, True, [-3, -2, -1, 3, 6], 'tfidf'],\n","['group', 'delete', 'group', 'delete', True, False, True, [-3, -1, 3, 5, 7], 'tfidf'] ]\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4m2WKZWIXjYK","executionInfo":{"status":"ok","timestamp":1617921607088,"user_tz":300,"elapsed":368901,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"f895fd2c-6ab8-4f16-c3d2-d237b44d56d3"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'linear'\n","C = 2\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print(f'conf_ID: {conf_ID},   tm_ID: {tm_ID}\\n')\n","\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  #print(tm_params_dict)\n","  text_model = TextModel(**tm_params_dict)\n","\n","  print('Fitting the text model')\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('\\nSaving text model and trained classifier\\n\\n')\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conf_ID: GQZgqx,   tm_ID: CgOJHi\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: hwmIFg,   tm_ID: bVkhBU\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: tgCmGg,   tm_ID: wxNaSh\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: fwZpdd,   tm_ID: WHTRQA\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: wavzCG,   tm_ID: iTLnGg\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cKtgm2OZVR3w"},"source":["## HS - sigmoid kernel"]},{"cell_type":"code","metadata":{"id":"GoHHa6nYVR3x"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['HS'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GgtXKkLDVR3y"},"source":["configurations_ids = ['bKgjxA', 'ddJgKe', 'qnVrDo', 'ZSDGIu', 'eJPzqU']\n","textmodels_ids = ['fabKkA', 'pRduGU', 'SoAVcr', 'bcYlZN', 'Nilquo']\n","\n","# HS sigmoid kernel\n","tm_settings_list = [ ['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 7], 'tfidf'],\n","['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 7], 'tfidf'],\n","['group', 'delete', 'group', 'delete', True, False, False, [-3, -1, 3, 7], 'tfidf'],\n","['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 6], 'tfidf'],\n","['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 6, 7], 'tfidf'] ]\n","\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wc0e5DmdVR3z","executionInfo":{"status":"ok","timestamp":1617919626639,"user_tz":300,"elapsed":331429,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"7c51b45a-1455-45e1-a06c-bd0f722e3194"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'sigmoid'\n","C = 1.41\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print(f'conf_ID: {conf_ID},   tm_ID: {tm_ID}\\n')\n","\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  #print(tm_params_dict)\n","  text_model = TextModel(**tm_params_dict)\n","\n","  print('Fitting the text model')\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('\\nSaving text model and trained classifier\\n\\n')\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conf_ID: bKgjxA,   tm_ID: fabKkA\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: ddJgKe,   tm_ID: pRduGU\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: qnVrDo,   tm_ID: SoAVcr\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: ZSDGIu,   tm_ID: bcYlZN\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: eJPzqU,   tm_ID: Nilquo\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4w-KNHUrwXR7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgajJP6KwYHN"},"source":["## TR - linear kernel"]},{"cell_type":"code","metadata":{"id":"NPAcK75wwYHQ"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['TR'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jflZASbNwYHS"},"source":["configurations_ids = ['OFznBK', 'peKOTV', 'NnIIjU', 'PFWLCY', 'cqPNUg']\n","textmodels_ids = ['pNqujl', 'MWagAt', 'yhmmRG', 'aiCCPb', 'qRFfIc']\n","\n","# TR linear kernel\n","tm_settings_list = [ ['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 6], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', True, False, True, [-3, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 6], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 7], 'tfidf'] ]\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWLtE_sXwYHU","executionInfo":{"status":"ok","timestamp":1622523205908,"user_tz":300,"elapsed":287058,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"9c7b2691-48f4-4eb7-bb67-e0a7ef0d94f4"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'linear'\n","C = 2\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print(f'conf_ID: {conf_ID},   tm_ID: {tm_ID}\\n')\n","\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  #print(tm_params_dict)\n","  text_model = TextModel(**tm_params_dict)\n","\n","  print('Fitting the text model')\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('\\nSaving text model and trained classifier\\n\\n')\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conf_ID: OFznBK,   tm_ID: pNqujl\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: peKOTV,   tm_ID: MWagAt\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: NnIIjU,   tm_ID: yhmmRG\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: PFWLCY,   tm_ID: aiCCPb\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: cqPNUg,   tm_ID: qRFfIc\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OiPpkuopwYHY"},"source":["## TR - sigmoid kernel"]},{"cell_type":"code","metadata":{"id":"oXB-YUdHwYHZ"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['TR'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gp02pbaHwYHe"},"source":["configurations_ids = ['ATGBKd', 'AjLonL', 'PDNKQY', 'ulFaFM', 'RVYzWK']\n","textmodels_ids = ['vKQhlC', 'tnRmpK', 'uIjYYW', 'xzUkgN', 'rdPtoi']\n","\n","# TR sigmoid kernel\n","tm_settings_list = [['group', 'delete', 'delete', 'delete', False, False, True, [-3, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 6], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-3, -1, 3, 6, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 5, 7], 'tfidf'] ]\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stPvogTXwYHg","executionInfo":{"status":"ok","timestamp":1622523851599,"user_tz":300,"elapsed":305542,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"1ad44c9b-5604-4194-9d36-c8be33381606"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'sigmoid'\n","C = 2\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print(f'conf_ID: {conf_ID},   tm_ID: {tm_ID}\\n')\n","\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  #print(tm_params_dict)\n","  text_model = TextModel(**tm_params_dict)\n","\n","  print('Fitting the text model')\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('\\nSaving text model and trained classifier\\n\\n')\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conf_ID: ATGBKd,   tm_ID: vKQhlC\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: AjLonL,   tm_ID: tnRmpK\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: PDNKQY,   tm_ID: uIjYYW\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: ulFaFM,   tm_ID: xzUkgN\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: RVYzWK,   tm_ID: rdPtoi\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VGxR7bFg3dcI"},"source":["## AG - linear kernel"]},{"cell_type":"code","metadata":{"id":"wGPAhszD3dcj"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['AG'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bZHYihf3dcm"},"source":["configurations_ids = ['wJPAHW', 'ejjQUP', 'ahlXxo', 'wxHotu', 'naYSFx']\n","textmodels_ids = ['JopFMW', 'OqAhDb', 'NflZGL', 'lrdGCb', 'lQVifv']\n","\n","# AG linear kernel\n","tm_settings_list = [['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-3, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 6, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', True, False, True, [-3, -1, 3, 6, 7], 'tfidf'] ]\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DyHicvL3dcn","executionInfo":{"status":"ok","timestamp":1622525161448,"user_tz":300,"elapsed":338480,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"921d299e-08fe-45fd-d8c4-6c8dfd6e16d1"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'linear'\n","C = 1.41\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print(f'conf_ID: {conf_ID},   tm_ID: {tm_ID}\\n')\n","\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  #print(tm_params_dict)\n","  text_model = TextModel(**tm_params_dict)\n","\n","  print('Fitting the text model')\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('\\nSaving text model and trained classifier\\n\\n')\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conf_ID: wJPAHW,   tm_ID: JopFMW\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: ejjQUP,   tm_ID: OqAhDb\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: ahlXxo,   tm_ID: NflZGL\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: wxHotu,   tm_ID: lrdGCb\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: naYSFx,   tm_ID: lQVifv\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oFR95rwt3dcr"},"source":["## AG - sigmoid kernel"]},{"cell_type":"code","metadata":{"id":"aXGQtQ_G3dcs"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['AG'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVjLy82M3dcu"},"source":["configurations_ids = ['cpagTE', 'jlugvH', 'GMUaEy', 'bwiAzB', 'kMJPac']\n","textmodels_ids = ['bOsLGf', 'TCbkrJ', 'OKbEvO', 'iIVaiv', 'sJCvyU']\n","\n","# TR sigmoid kernel\n","tm_settings_list = [ ['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'delete', 'delete', False, False, True, [-2, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', False, False, True, [-2, -1, 3, 6, 7], 'tfidf'],\n"," ['group', 'delete', 'group', 'delete', True, False, False, [-3, -1, 3, 7], 'tfidf'],\n"," ['group', 'delete', 'delete', 'delete', False, False, True, [-3, -1, 3, 6, 7], 'tfidf'] ]\n","\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1Wj1Dug3dcv","executionInfo":{"status":"ok","timestamp":1622525769215,"user_tz":300,"elapsed":324099,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"167e7df0-749c-41fa-d685-48585b164921"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'sigmoid'\n","C = 1.41\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print(f'conf_ID: {conf_ID},   tm_ID: {tm_ID}\\n')\n","\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  #print(tm_params_dict)\n","  text_model = TextModel(**tm_params_dict)\n","\n","  print('Fitting the text model')\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('\\nSaving text model and trained classifier\\n\\n')\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["conf_ID: cpagTE,   tm_ID: bOsLGf\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: jlugvH,   tm_ID: TCbkrJ\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: GMUaEy,   tm_ID: OKbEvO\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: bwiAzB,   tm_ID: iIVaiv\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n","conf_ID: kMJPac,   tm_ID: sJCvyU\n","\n","Fitting the text model\n","Transforming the training messages\n","Training SVC\n","\n","Saving text model and trained classifier\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CcibWdBQd_9V"},"source":["## HTA - linear kernel"]},{"cell_type":"code","metadata":{"id":"LOU6dUU_Pv5r","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1622606455357,"user_tz":300,"elapsed":994,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"3a7026e4-7d04-4c6f-99b1-e513cc19fe3b"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['HTA'].to_list()\n","\n","X_test, Y_test = dataset_utils.importTestDataForSVM()\n","X_test = X_test['text'].to_list()\n","Y_test = Y_test['HTA'].to_list()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-bda3997b6829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportTrainDataForSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HTA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportTestDataForSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataset_utils' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ksD17LtWV4wg"},"source":["configurations_ids = ['eKpEEc', 'lFupON', 'XulowM', 'JonAxF', 'Etgzct']\n","textmodels_ids = ['wKlLLQ', 'pTurDN', 'HsOAlr', 'CmFmfJ', 'YXTXdt']\n","\n","# HTA linear kernel\n","tm_settings_list = [ ['group', 'delete', 'group', 'group', True, False, True, [-3, -2, -1, 3], 'tfidf'],\n","['group', 'delete', 'group', 'delete', True, False, True, [-3, -2, -1, 3, 4], 'tfidf'],\n","['group', 'delete', 'group', 'group', True, False, True, [-2, -1, 3], 'tfidf'],\n","['group', 'delete', 'group', 'group', True, False, True, [-3, -1, 3], 'tfidf'],\n","['group', 'delete', 'group', 'group', True, False, True, [-2, -1, 3, 4, 7], 'tfidf'] ]\n","\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7NIwfav2Zndg"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'linear'\n","C = 2\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print('\\n')\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  print(tm_params_dict)\n","\n","  text_model = TextModel(**tm_params_dict)\n","\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training and test messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","  X_test_transformed = text_model.transform(X_test)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('Evaluating classifier')\n","  # Evaluate on the test data\n","  # make predictions\n","  pred_labels = classifier.predict(X_test_transformed)\n","\n","  # change the labels format (from five_classes_format to 3dims_format)\n","  pred_labels = [dataset_utils.mapTo3DimsFormat(label) for label in pred_labels]\n","  test_labels = [dataset_utils.mapTo3DimsFormat(label) for label in Y_test]\n","\n","  # get labels per task\n","  pred_hate_labels   = [label[0] for label in pred_labels]\n","  pred_target_labels = [label[1] for label in pred_labels]\n","  pred_aggr_labels   = [label[2] for label in pred_labels]\n","\n","  test_hate_labels   = [label[0] for label in test_labels]\n","  test_target_labels = [label[1] for label in test_labels]\n","  test_aggr_labels   = [label[2] for label in test_labels]\n","\n","  # evaluate the preditions\n","  evaluation = eval_utils.evaluatePredictions((pred_hate_labels,pred_target_labels,pred_aggr_labels),\n","                                              (test_hate_labels,test_target_labels,test_aggr_labels))\n","\n","  print(evaluation)\n","  print(\"\\n\")\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CK6vK73regWJ"},"source":["## HTA - sigmoid kernel"]},{"cell_type":"code","metadata":{"id":"718eeBlHegWL"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()\n","X_train = X_train['text'].to_list()\n","Y_train = Y_train['HTA'].to_list()\n","\n","X_test, Y_test = dataset_utils.importTestDataForSVM()\n","X_test = X_test['text'].to_list()\n","Y_test = Y_test['HTA'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yvTgPF5FegWO"},"source":["configurations_ids = ['KAcOYq', 'bmCbAB', 'pcPfNL', 'wNOXbH', 'hVEaUj']\n","textmodels_ids = ['djwYeF', 'TqHwoB', 'sUlSKy', 'CgdcXu', 'oDWZfJ']\n","\n","# HTA sigmoid kernel\n","tm_settings_list = [ ['group', 'delete', 'delete', 'delete', False, False, True, [-3, -1, 3, 7], 'tfidf'],\n","['group', 'group', 'group', 'delete', True, False, True, [-1, 3, 7], 'tfidf'],\n","['group', 'delete', 'delete', 'delete', False, False, True, [-3, -2, -1, 3, 6], 'tfidf'],\n","['group', 'group', 'group', 'delete', True, False, True, [-3, -1, 3, 6], 'tfidf'],\n","['group', 'delete', 'group', 'delete', False, False, True, [-3, -2, -1, 3, 5], 'tfidf'] ]\n","\n","\n","tm_parameters_keys = ['num_option',\n"," 'usr_option',\n"," 'url_option',\n"," 'hashtag_option',\n"," 'del_punc',\n"," 'del_dup',\n"," 'del_diac',\n"," 'token_list',\n"," 'weighting']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsaUwTcKegWP","executionInfo":{"status":"ok","timestamp":1617869271786,"user_tz":300,"elapsed":543522,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"03136880-c590-4d10-aa4e-4b9ddc265cd6"},"source":["from microtc.textmodel import TextModel\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn import svm\n","\n","kernel = 'sigmoid'\n","C = 2\n","\n","for conf_ID, tm_ID, tm_settings in zip(configurations_ids, textmodels_ids, tm_settings_list):\n","  print('\\n')\n","  print(conf_ID, tm_ID)\n","  tm_params_dict = dict(zip(tm_parameters_keys, tm_settings))\n","  print(tm_params_dict)\n","\n","  text_model = TextModel(**tm_params_dict)\n","\n","  # fit the text_model to the training data\n","  text_model.fit(X_train)\n","\n","  # Instantiate the svm classifier\n","  classifier = svm.SVC(kernel=kernel, C=C)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  print(\"Transforming the training and test messages\")\n","  X_train_tranformed = text_model.transform(X_train)\n","  X_test_transformed = text_model.transform(X_test)\n","\n","  # fit the classifier\n","  print('Training SVC')\n","  classifier.fit(X_train_tranformed, Y_train)\n","\n","  print('Evaluating classifier')\n","  # Evaluate on the test data\n","  # make predictions\n","  pred_labels = classifier.predict(X_test_transformed)\n","\n","  # change the labels format (from five_classes_format to 3dims_format)\n","  pred_labels = [dataset_utils.mapTo3DimsFormat(label) for label in pred_labels]\n","  test_labels = [dataset_utils.mapTo3DimsFormat(label) for label in Y_test]\n","\n","  # get labels per task\n","  pred_hate_labels   = [label[0] for label in pred_labels]\n","  pred_target_labels = [label[1] for label in pred_labels]\n","  pred_aggr_labels   = [label[2] for label in pred_labels]\n","\n","  test_hate_labels   = [label[0] for label in test_labels]\n","  test_target_labels = [label[1] for label in test_labels]\n","  test_aggr_labels   = [label[2] for label in test_labels]\n","\n","  # evaluate the preditions\n","  evaluation = eval_utils.evaluatePredictions((pred_hate_labels,pred_target_labels,pred_aggr_labels),\n","                                              (test_hate_labels,test_target_labels,test_aggr_labels))\n","\n","  print(evaluation)\n","  print(\"\\n\")\n","\n","  with open(f'./text_models/{tm_ID}/G.tm', 'wb') as file_handler:\n","    pickle.dump(text_model, file_handler)\n","\n","  with open(f'./trained_models/{conf_ID}/G.svc', 'wb') as file_handler:\n","    pickle.dump(classifier, file_handler)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","KAcOYq djwYeF\n","{'num_option': 'group', 'usr_option': 'delete', 'url_option': 'delete', 'hashtag_option': 'delete', 'del_punc': False, 'del_dup': False, 'del_diac': True, 'token_list': [-3, -1, 3, 7], 'weighting': 'tfidf'}\n","Transforming the training and test messages\n","Training SVC\n","Evaluating classifier\n","{'A_acc': 0.765, 'B1_acc': 0.869375, 'B2_acc': 0.765625, 'A1_f1': 0.7557109072481094, 'B1_f1': 0.8204828817221619, 'B2_f1': 0.7368604557840046, 'F1_multi': 0.7710180815847586, 'EMR': 0.690625}\n","\n","\n","\n","\n","bmCbAB TqHwoB\n","{'num_option': 'group', 'usr_option': 'group', 'url_option': 'group', 'hashtag_option': 'delete', 'del_punc': True, 'del_dup': False, 'del_diac': True, 'token_list': [-1, 3, 7], 'weighting': 'tfidf'}\n","Transforming the training and test messages\n","Training SVC\n","Evaluating classifier\n","{'A_acc': 0.755, 'B1_acc': 0.863125, 'B2_acc': 0.75875, 'A1_f1': 0.7447916666666667, 'B1_f1': 0.8145284953359527, 'B2_f1': 0.7279961383907729, 'F1_multi': 0.7624387667977975, 'EMR': 0.6825}\n","\n","\n","\n","\n","pcPfNL sUlSKy\n","{'num_option': 'group', 'usr_option': 'delete', 'url_option': 'delete', 'hashtag_option': 'delete', 'del_punc': False, 'del_dup': False, 'del_diac': True, 'token_list': [-3, -2, -1, 3, 6], 'weighting': 'tfidf'}\n","Transforming the training and test messages\n","Training SVC\n","Evaluating classifier\n","{'A_acc': 0.765, 'B1_acc': 0.8675, 'B2_acc': 0.76875, 'A1_f1': 0.7555866489206974, 'B1_f1': 0.818069086548054, 'B2_f1': 0.7397623749144997, 'F1_multi': 0.7711393701277504, 'EMR': 0.689375}\n","\n","\n","\n","\n","wNOXbH CgdcXu\n","{'num_option': 'group', 'usr_option': 'group', 'url_option': 'group', 'hashtag_option': 'delete', 'del_punc': True, 'del_dup': False, 'del_diac': True, 'token_list': [-3, -1, 3, 6], 'weighting': 'tfidf'}\n","Transforming the training and test messages\n","Training SVC\n","Evaluating classifier\n","{'A_acc': 0.758125, 'B1_acc': 0.856875, 'B2_acc': 0.75625, 'A1_f1': 0.7490043474295442, 'B1_f1': 0.8073889266506121, 'B2_f1': 0.7264616765795084, 'F1_multi': 0.7609516502198882, 'EMR': 0.68}\n","\n","\n","\n","\n","hVEaUj oDWZfJ\n","{'num_option': 'group', 'usr_option': 'delete', 'url_option': 'group', 'hashtag_option': 'delete', 'del_punc': False, 'del_dup': False, 'del_diac': True, 'token_list': [-3, -2, -1, 3, 5], 'weighting': 'tfidf'}\n","Transforming the training and test messages\n","Training SVC\n","Evaluating classifier\n","{'A_acc': 0.764375, 'B1_acc': 0.86625, 'B2_acc': 0.763125, 'A1_f1': 0.7566539923954373, 'B1_f1': 0.818605636787455, 'B2_f1': 0.7362192616488297, 'F1_multi': 0.7704929636105741, 'EMR': 0.685}\n","\n","\n"],"name":"stdout"}]}]}