{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVC - EVALUATION OVER TEST SET.ipynb","provenance":[],"collapsed_sections":["CcibWdBQd_9V","CK6vK73regWJ"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RfekjF9mkdWy"},"source":["# Ajustes iniciales"]},{"cell_type":"markdown","metadata":{"id":"zgdSkhxZdv0_"},"source":["## Conexión a google drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rEA8wkz2HzN","executionInfo":{"status":"ok","timestamp":1623135422070,"user_tz":300,"elapsed":26897,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"2beb43be-7495-4ab8-b869-0e4689d86cc7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Crq_ww9d2GNh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623135464730,"user_tz":300,"elapsed":197,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"5770203c-1de0-41ef-de57-d0acb07537a5"},"source":["%cd ./drive/MyDrive/Colab Notebooks/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"PwoDWvGgk8oT","executionInfo":{"status":"ok","timestamp":1623135465099,"user_tz":300,"elapsed":31,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"08e9401c-a68f-4aa7-ad53-6d0e5d9121a4"},"source":["%pwd"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Colab Notebooks'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"qDN_7IBkXjrl"},"source":["## Instalar microTC"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRhkanwGXjrw","executionInfo":{"status":"ok","timestamp":1623135470915,"user_tz":300,"elapsed":5838,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"e6d20737-a677-4174-9291-48da4fc91847"},"source":["%pip install git+https://github.com/felipeRmBr/microtc.git#egg=microtc"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting microtc\n","  Cloning https://github.com/felipeRmBr/microtc.git to /tmp/pip-install-xehaahae/microtc\n","  Running command git clone -q https://github.com/felipeRmBr/microtc.git /tmp/pip-install-xehaahae/microtc\n","Building wheels for collected packages: microtc\n","  Building wheel for microtc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for microtc: filename=microtc-2.2.8-cp37-none-any.whl size=60798 sha256=64d2cabfe411c88c52a7ba01fa2e41c4782955f4d9ed562e1d1acb7ac5e7299d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-q1qicgpg/wheels/73/00/4e/a4e2fc519599a41145f1740a75c80f390d4bcef72fed066f56\n","Successfully built microtc\n","Installing collected packages: microtc\n","Successfully installed microtc-2.2.8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8fz70fVKJJ11"},"source":["## Importar modulos *_utils\n"]},{"cell_type":"code","metadata":{"id":"Vm7v_xFpU3sr","executionInfo":{"status":"ok","timestamp":1623135472924,"user_tz":300,"elapsed":2024,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}}},"source":["import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n","from my_utils import dataset_utils\n","from my_utils import eval_utils\n","from my_utils import svc_utils #(depends on microtc)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jcdhuxpmcmbw","executionInfo":{"status":"ok","timestamp":1623135472939,"user_tz":300,"elapsed":35,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}}},"source":["import pickle"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7RtT5IB7Aqo3"},"source":["# Utils"]},{"cell_type":"markdown","metadata":{"id":"t7qhR_rKnXjX"},"source":["## evaluateClassifiersOnTest()"]},{"cell_type":"code","metadata":{"id":"SjBR5fHii5qR","executionInfo":{"status":"ok","timestamp":1623136145234,"user_tz":300,"elapsed":284,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}}},"source":["def evaluateClassifiersOnTest(task, conf_ids, tm_ids, kernel):\n","  print('Loading test data')\n","  X_test, Y_test = dataset_utils.importTestDataForSVM()\n","  X_test = X_test['text'].to_list()\n","\n","  print('Evaluating classifiers...')\n","  print()\n","  merged_results = DataFrame()\n","  for config_ID, tm_ID in zip(conf_ids, tm_ids):\n","    print(f'config_ID: {config_ID},  tm_ID: {tm_ID}')\n","\n","    merged_results = merged_results.append(evaluateTrainedModels(X_test, Y_test, task, config_ID, tm_ID, f'SVC-{kernel}', 7),\n","                          ignore_index=True)\n","\n","  results_file = f'./Results/final/SVC-{kernel}_{task}_TEST.df'\n","  with open(results_file, 'wb') as file_handler:\n","    pickle.dump(merged_results, file_handler) \n","\n","  print()\n","  print(f'Results saved to: {results_file}')"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D5DYU2Dyw3Pd"},"source":["### evaluateTrainedModels()"]},{"cell_type":"code","metadata":{"id":"GjZJEfL6w3Pg","executionInfo":{"status":"ok","timestamp":1623136017005,"user_tz":300,"elapsed":195,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}}},"source":["\n","from pandas import DataFrame\n","import numpy as np\n","from os import path, makedirs\n","from  tensorflow.keras.utils import to_categorical\n","\n","def evaluateTrainedModels(X_test, Y_test, task, \n","                          config_ID, tm_ID, arch_label, n_folds,\n","                          verbose=False):\n","\n","  evaluations_record = list()\n","\n","  if task=='HTA':\n","    n_classes = 5\n","  else:\n","    n_classes = 2\n","\n","  # lasses_votes_sum to generate an ensemble model \n","  classes_votes_sum = np.zeros((len(Y_test),n_classes))\n","\n","  # EVALUATE THE FOLDS CLASSIFIERS ---------------------------------------------\n","  for fold_idx in range(n_folds):\n","    if verbose:\n","      print('\\nEvaluating data-fold {}'.format(fold_idx))\n","\n","    # load the text_model \n","    with open(f'./text_models/{tm_ID}/F{fold_idx}.tm', 'rb') as file_handler:\n","      text_model = pickle.load(file_handler)\n","  \n","    # load the classifier\n","    with open(f'./trained_models/{config_ID}/F{fold_idx}.svc', 'rb') as file_handler:\n","      classifier = pickle.load(file_handler)\n","\n","    # transform X_train and X_test using the fitted text_model\n","    if verbose:\n","      print(\"Transforming the test messages\")\n","    X_test_transformed = text_model.transform(X_test)\n","\n","    # Evaluate on the test data\n","    # make predictions\n","    labels_predictions = classifier.predict(X_test_transformed)\n","\n","    classes_votes_sum += to_categorical(labels_predictions, num_classes=n_classes)\n","\n","    # evaluate the preditions\n","    evaluation = evaluatePredictions(task, Y_test[task], labels_predictions)\n","    \n","    model_results_dict = {'conf_id': config_ID,\n","                          'tm_ID': tm_ID,\n","                          'model_type': 'F',\n","                          'architecture': arch_label,\n","                          **evaluation}\n","\n","    evaluations_record.append(model_results_dict) \n","\n","  # EVALUATE THE FULL-DATASET MODEL --------------------------------------------\n","  if verbose:\n","      print('\\nEvaluating full-dataset model'.format(fold_idx))\n","\n","  # load the text model \n","  with open(f'./text_models/{tm_ID}/G.tm', 'rb') as file_handler:\n","    text_model = pickle.load(file_handler)\n","\n","  # load the classifier\n","  with open(f'./trained_models/{config_ID}/G.svc', 'rb') as file_handler:\n","    classifier = pickle.load(file_handler)\n","\n","  # transform X_train and X_test using the fitted text_model\n","  if verbose:\n","      print(\"Transforming the test messages\")\n","  X_test_transformed = text_model.transform(X_test)\n","\n","  # Evaluate on the test data\n","  # make predictions\n","  labels_predictions = classifier.predict(X_test_transformed)\n","\n","  # evaluate the preditions\n","  evaluation = evaluatePredictions(task, Y_test[task], labels_predictions)\n","  \n","  model_results_dict = {'conf_id': config_ID,\n","                        'tm_ID': tm_ID,\n","                        'model_type': 'G',\n","                        'architecture': arch_label,\n","                        **evaluation}                       \n","\n","  evaluations_record.append(model_results_dict) \n","\n","  # EVALUATE THE ENSEMBLE\n","  if verbose:\n","      print('\\nEvaluating MAJORITY VOTING ENSEMBLE')\n","\n","  # turn the classes votes into an array of classes predictions\n","  class_pred_array = np.array([classes_votes.argmax() for classes_votes in classes_votes_sum]).reshape(-1,1)\n","\n","  # evaluate the preditions\n","  evaluation = evaluatePredictions(task, Y_test[task], class_pred_array)\n","  \n","  model_results_dict = {'conf_id': config_ID,\n","                        'tm_ID': tm_ID,\n","                        'model_type': 'E1',\n","                        'architecture': arch_label,\n","                        **evaluation}\n","\n","  evaluations_record.append(model_results_dict) \n","\n","  evaluations_results_df = DataFrame(evaluations_record)\n","\n","  return evaluations_results_df"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3QSKclR7zsd"},"source":["### evaluatePredictions()"]},{"cell_type":"code","metadata":{"id":"kKVWYGjSQ16W","executionInfo":{"status":"ok","timestamp":1623136020544,"user_tz":300,"elapsed":253,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}}},"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def evaluatePredictions(task, val_labels, pred_labels, verbose=False):\n","\n","  if task=='HTA':\n","\n","    # get the correspondig predicted and val (target) labels for each task\n","    pred_HS_labels, pred_TR_labels, pred_AG_labels = dataset_utils.getLabelsPerTask(pred_labels)\n","    val_HS_labels, val_TR_labels, val_AG_labels = dataset_utils.getLabelsPerTask(val_labels)\n","\n","    # compute ACC, PREC, RECALL and F1 metrics\n","    HS_acc, HS_prec, HS_recall, HS_f1 = compute_metrics(val_HS_labels, pred_HS_labels)\n","    AG_acc, AG_prec, AG_recall, AG_f1 = compute_metrics(val_AG_labels, pred_AG_labels)   \n","    TR_acc, TR_prec, TR_recall, TR_f1 = compute_metrics(val_TR_labels, pred_TR_labels)\n","\n","    F1_multi = (HS_f1+ AG_f1 + TR_f1)/3\n","\n","    EMR = computeEMR(list(zip(val_HS_labels, val_TR_labels, val_AG_labels)),\n","                    list(zip(pred_HS_labels, pred_TR_labels, pred_AG_labels)))\n","\n","    results_dict = {'HS_acc':HS_acc,\n","                    'HS_prec':HS_prec,\n","                    'HS_recall':HS_recall,\n","                    'HS_f1':HS_f1,\n","                    'AG_acc':AG_acc,\n","                    'AG_prec':AG_prec,\n","                    'AG_recall':AG_recall,\n","                    'AG_f1':AG_f1,\n","                    'TR_acc':TR_acc,\n","                    'TR_prec':TR_prec,\n","                    'TR_recall':TR_recall,\n","                    'TR_f1':TR_f1,\n","                    'F1_multi':F1_multi,\n","                    'EMR':EMR}\n","\n","    if verbose:\n","      print('EMR = ', EMR)\n","      print('F1_multi = ', F1_multi)\n","      print()\n","\n","    return results_dict\n","\n","  if task in ['HS', 'TR', 'AG']:\n","    # compute ACC, PREC, RECALL and F1 metrics\n","    acc, prec, recall, f1_macro = compute_metrics(val_labels, pred_labels)\n","\n","    results_dict = {'acc':acc,\n","                    'prec':prec,\n","                    'recall':recall,\n","                    'f1-macro':f1_macro}\n","\n","    if verbose:\n","      print('Acc = ', acc)\n","      print('F1_macro = ', f1_macro)\n","      print()\n","\n","    return results_dict\n","\n","def compute_metrics(target, predicted):\n","    accuracy = accuracy_score(target, predicted)\n","    precision = precision_score(target, predicted, average=\"macro\")\n","    recall = recall_score(target, predicted, average=\"macro\")\n","    f1 = f1_score(target, predicted, average=\"macro\")\n","    \n","    return accuracy, precision, recall, f1    \n","\n","def computeEMR(test_labels, pred_labels):\n","  total_instances = len(test_labels)\n","  exact_match_count= 0\n","  for gold, pred in zip(test_labels, pred_labels):\n","    #print(gold, pred)\n","    if gold == pred:\n","      exact_match_count += 1\n","\n","  return exact_match_count/total_instances\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ph-r7nmxBC5R"},"source":["### labels_utils"]},{"cell_type":"code","metadata":{"id":"tawlyUzASU-s","executionInfo":{"status":"ok","timestamp":1623136022961,"user_tz":300,"elapsed":188,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}}},"source":["#**************************     getLabelsPerTask()    **************************\n","def getLabelsPerTask(HTA_labels):\n","\n","    HS_labels = list()\n","    TR_labels = list()\n","    AG_labels = list()\n","\n","    for HTA_label in HTA_labels:\n","        HS_label, TR_label, AG_label = mapTo3DimsFormat(HTA_label)\n","\n","        HS_labels.append(HS_label)\n","        TR_labels.append(TR_label)\n","        AG_labels.append(AG_label)\n","\n","    HS_labels = np.array(HS_labels).reshape(-1,1)\n","    TR_labels = np.array(TR_labels).reshape(-1,1)\n","    AG_labels = np.array(AG_labels).reshape(-1,1)\n","\n","    return (HS_labels, TR_labels, AG_labels)\n","\n","#**************************     mapTo3DimsFormat()    ************************** \n","def mapTo3DimsFormat(AB_label):\n","  '''\n","  Maps label in five_classes_format to 3 dims labeling.\n","\n","    0 -> (0,0,0)  [HT = 0, TR = 0, AG = 0]\n","    1 -> (1,0,0)  [HT = 1, TR = 0, AG = 0]\n","    2 -> (1,0,1)  [HT = 1, TR = 0, AG = 1]\n","    3 -> (1,1,0)  [HT = 1, TR = 1, AG = 0]\n","    4 -> (1,1,1)  [HT = 1, TR = 1, AG = 1]\n","\n","  inpunt:\n","  label    - int, label in five_classes_format\n","\n","  output:\n","  (H,T,A)  - ints tuple, labeling in 3 dims format\n","\n","  '''\n","  if AB_label == 0:\n","    return(0,0,0)\n","\n","  elif AB_label == 1:\n","    return(1,0,0)\n","\n","  elif AB_label == 2:\n","    return(1,0,1)\n","\n","  elif AB_label == 3:\n","    return(1,1,0)\n","\n","  elif AB_label == 4:\n","    return(1,1,1)\n"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1LPJhrOnwtE5"},"source":["# EVALUATE TRAINED MODELS ON TEST DATA"]},{"cell_type":"markdown","metadata":{"id":"DUTVBnpvbFJp"},"source":["## HS - linear kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGmvRd_8lNP7","executionInfo":{"status":"ok","timestamp":1623136426909,"user_tz":300,"elapsed":277749,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"a55b2aae-ea81-4de3-f2ac-dcb61c09d8d0"},"source":["configurations_ids = ['GQZgqx', 'hwmIFg', 'tgCmGg', 'fwZpdd', 'wavzCG']\n","textmodels_ids = ['CgOJHi', 'bVkhBU', 'wxNaSh', 'WHTRQA', 'iTLnGg']\n","\n","evaluateClassifiersOnTest('HS', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'LINEAR')"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: GQZgqx,  tm_ID: CgOJHi\n","config_ID: hwmIFg,  tm_ID: bVkhBU\n","config_ID: tgCmGg,  tm_ID: wxNaSh\n","config_ID: fwZpdd,  tm_ID: WHTRQA\n","config_ID: wavzCG,  tm_ID: iTLnGg\n","\n","Results saved to: ./Results/final/SVC-LINEAR_HS_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aWpvSs4nbEoU"},"source":["## HS - sigmoid kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fr292TzTpXxP","executionInfo":{"status":"ok","timestamp":1623136759183,"user_tz":300,"elapsed":332963,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"cd941779-c0a1-4ed9-beaa-2262b4b61e6a"},"source":["configurations_ids = ['bKgjxA', 'ddJgKe', 'qnVrDo', 'ZSDGIu', 'eJPzqU']\n","textmodels_ids = ['fabKkA', 'pRduGU', 'SoAVcr', 'bcYlZN', 'Nilquo']\n","\n","evaluateClassifiersOnTest('HS', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'SIGMOID')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: bKgjxA,  tm_ID: fabKkA\n","config_ID: ddJgKe,  tm_ID: pRduGU\n","config_ID: qnVrDo,  tm_ID: SoAVcr\n","config_ID: ZSDGIu,  tm_ID: bcYlZN\n","config_ID: eJPzqU,  tm_ID: Nilquo\n","\n","Results saved to: ./Results/final/SVC-SIGMOID_HS_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5ZxRymcq6tn5"},"source":["## TR - linear kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFEbXoUguCwB","executionInfo":{"status":"ok","timestamp":1623137059378,"user_tz":300,"elapsed":300234,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"c9fce907-fc37-4b63-a8a8-469c16c46c3e"},"source":["configurations_ids = ['OFznBK', 'peKOTV', 'NnIIjU', 'PFWLCY', 'cqPNUg']\n","textmodels_ids = ['pNqujl', 'MWagAt', 'yhmmRG', 'aiCCPb', 'qRFfIc']\n","\n","evaluateClassifiersOnTest('TR', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'LINEAR')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: OFznBK,  tm_ID: pNqujl\n","config_ID: peKOTV,  tm_ID: MWagAt\n","config_ID: NnIIjU,  tm_ID: yhmmRG\n","config_ID: PFWLCY,  tm_ID: aiCCPb\n","config_ID: cqPNUg,  tm_ID: qRFfIc\n","\n","Results saved to: ./Results/final/SVC-LINEAR_TR_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LCEj7INt6tn_"},"source":["## TR - sigmoid kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0kaKa5kuT8k","executionInfo":{"status":"ok","timestamp":1623137385543,"user_tz":300,"elapsed":326204,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"64f3a099-62d7-428d-dfa6-c9d5f97e16af"},"source":["configurations_ids = ['ATGBKd', 'AjLonL', 'PDNKQY', 'ulFaFM', 'RVYzWK']\n","textmodels_ids = ['vKQhlC', 'tnRmpK', 'uIjYYW', 'xzUkgN', 'rdPtoi']\n","\n","evaluateClassifiersOnTest('TR', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'SIGMOID')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: ATGBKd,  tm_ID: vKQhlC\n","config_ID: AjLonL,  tm_ID: tnRmpK\n","config_ID: PDNKQY,  tm_ID: uIjYYW\n","config_ID: ulFaFM,  tm_ID: xzUkgN\n","config_ID: RVYzWK,  tm_ID: rdPtoi\n","\n","Results saved to: ./Results/final/SVC-SIGMOID_TR_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xbapJQ4MFoc4"},"source":["## AG - linear kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6xrLddbyTpL","executionInfo":{"status":"ok","timestamp":1623137723706,"user_tz":300,"elapsed":338200,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"87875c8c-328a-4d1c-ecba-80b6c5b6194c"},"source":["configurations_ids = ['wJPAHW', 'ejjQUP', 'ahlXxo', 'wxHotu', 'naYSFx']\n","textmodels_ids = ['JopFMW', 'OqAhDb', 'NflZGL', 'lrdGCb', 'lQVifv']\n","\n","evaluateClassifiersOnTest('AG', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'LINEAR')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: wJPAHW,  tm_ID: JopFMW\n","config_ID: ejjQUP,  tm_ID: OqAhDb\n","config_ID: ahlXxo,  tm_ID: NflZGL\n","config_ID: wxHotu,  tm_ID: lrdGCb\n","config_ID: naYSFx,  tm_ID: lQVifv\n","\n","Results saved to: ./Results/final/SVC-LINEAR_AG_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cGs7ZZjzFodG"},"source":["## AG - sigmoid kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HA6uYER41RrF","executionInfo":{"status":"ok","timestamp":1623138060612,"user_tz":300,"elapsed":336950,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"511b6513-f7b4-4291-ccb4-4a80b2aa25f2"},"source":["configurations_ids = ['cpagTE', 'jlugvH', 'GMUaEy', 'bwiAzB', 'kMJPac']\n","textmodels_ids = ['bOsLGf', 'TCbkrJ', 'OKbEvO', 'iIVaiv', 'sJCvyU']\n","\n","evaluateClassifiersOnTest('AG', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'SIGMOID')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: cpagTE,  tm_ID: bOsLGf\n","config_ID: jlugvH,  tm_ID: TCbkrJ\n","config_ID: GMUaEy,  tm_ID: OKbEvO\n","config_ID: bwiAzB,  tm_ID: iIVaiv\n","config_ID: kMJPac,  tm_ID: sJCvyU\n","\n","Results saved to: ./Results/final/SVC-SIGMOID_AG_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wv24dML6bD5L"},"source":["## HTA - linear kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gvuLD4X1h33","executionInfo":{"status":"ok","timestamp":1623138384701,"user_tz":300,"elapsed":324161,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"240610d0-0c3e-495c-cf76-6f4ea99510ca"},"source":["configurations_ids = ['eKpEEc', 'lFupON', 'XulowM', 'JonAxF', 'Etgzct']\n","textmodels_ids = ['wKlLLQ', 'pTurDN', 'HsOAlr', 'CmFmfJ', 'YXTXdt']\n","\n","evaluateClassifiersOnTest('HTA', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'LINEAR')"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: eKpEEc,  tm_ID: wKlLLQ\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"},{"output_type":"stream","text":["config_ID: lFupON,  tm_ID: pTurDN\n","config_ID: XulowM,  tm_ID: HsOAlr\n","config_ID: JonAxF,  tm_ID: CmFmfJ\n","config_ID: Etgzct,  tm_ID: YXTXdt\n","\n","Results saved to: ./Results/final/SVC-LINEAR_HTA_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E7hWj0nY6vLN"},"source":["## HTA - sigmoid kernel"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R6vh-8fh1zRx","executionInfo":{"status":"ok","timestamp":1623138715423,"user_tz":300,"elapsed":330926,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"358b822c-3399-4fb6-863b-f2a134815ad4"},"source":["configurations_ids = ['KAcOYq', 'bmCbAB', 'pcPfNL', 'wNOXbH', 'hVEaUj']\n","textmodels_ids = ['djwYeF', 'TqHwoB', 'sUlSKy', 'CgdcXu', 'oDWZfJ']\n","\n","evaluateClassifiersOnTest('HTA', \n","                          configurations_ids,\n","                          textmodels_ids,\n","                          'SIGMOID')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Loading test data\n","Evaluating classifiers...\n","\n","config_ID: KAcOYq,  tm_ID: djwYeF\n","config_ID: bmCbAB,  tm_ID: TqHwoB\n","config_ID: pcPfNL,  tm_ID: sUlSKy\n","config_ID: wNOXbH,  tm_ID: CgdcXu\n","config_ID: hVEaUj,  tm_ID: oDWZfJ\n","\n","Results saved to: ./Results/final/SVC-SIGMOID_HTA_TEST.df\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5HAe1XMLYV3N"},"source":["# EVALUATE TRAINED MODELS ON VALIDATION DATA"]},{"cell_type":"markdown","metadata":{"id":"mQH5erIAYV3Q"},"source":["## Utils"]},{"cell_type":"markdown","metadata":{"id":"6mXUSCuXYV3R"},"source":["### evaluateTrainedModelsOnValidationData()"]},{"cell_type":"code","metadata":{"id":"vTAo_WgAYV3S"},"source":["\n","from pandas import DataFrame\n","import numpy as np\n","from os import path, makedirs\n","from  tensorflow.keras.utils import to_categorical\n","\n","def evaluateTrainedModelsOnValidationData(X_train, Y_train, task, \n","                                          config_ID, tm_ID, arch_label, n_folds):\n","  \n","  data_splits = getDataSplits(X_train, Y_train, task, n_folds)\n","\n","  evaluations_record = list()\n","\n","  # EVALUATE THE FOLDS CLASSIFIERS ---------------------------------------------\n","  for fold_idx in range(n_folds):\n","    print('\\nEvaluating data-fold {}'.format(fold_idx))\n","\n","    # load the text_model \n","    with open(f'./text_models/{tm_ID}/F{fold_idx}.tm', 'rb') as file_handler:\n","      text_model = pickle.load(file_handler)\n","  \n","    # load the classifier\n","    with open(f'./trained_models/{config_ID}/F{fold_idx}.svc', 'rb') as file_handler:\n","      classifier = pickle.load(file_handler)\n","\n","    # transform X_train and X_test using the fitted text_model\n","    print(\"Transforming the validation messages\")\n","    x_train, y_train, x_val, y_val = data_splits[fold_idx]\n","     \n","    # x_train = text_model.transform(x_train)\n","    x_val_transformed   = text_model.transform(x_val)\n","\n","    # Evaluate on the validation data\n","    # make predictions\n","    labels_predictions = classifier.predict(x_val_transformed)\n","\n","    # evaluate the preditions\n","    evaluation = evaluatePredictions(task, y_val, labels_predictions)\n","    \n","    model_results_dict = {'conf_id': config_ID,\n","                          'tm_ID': tm_ID,\n","                          'model_type': 'F',\n","                          'architecture': arch_label,\n","                          **evaluation}\n","\n","    evaluations_record.append(model_results_dict) \n","\n","  evaluations_results_df = DataFrame(evaluations_record)\n","\n","  return evaluations_results_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ee9llOqRh81J"},"source":["### getDataSplits()"]},{"cell_type":"code","metadata":{"id":"kJ1VyIX5h7CU"},"source":["def getDataSplits(X_train, Y_train, task, n_folds):\n","  '''\n","  splits train data into k folds for cross validation.\n","\n","  input\n","  X_train  - pd.DataFrame, X_train.columns() = ['text','kfold']\n","  Y_train  - pd.DataFrame, Y_train.columns() = ['HS', 'TR', 'AG', 'ATG', 'kfold']\n","  task     - str, valid tasks = ['HS', 'TR', 'AG', 'ATG']\n","  n_folds  - int, number of folds for cross validation\n","\n","  output\n","  data_splits_list  - list with n_folds different splits of the train data\n","\n","  '''\n","  data_splits_list = []\n","\n","  for K in range (n_folds):\n","    train_mask  = X_train.kfold==K\n","    x_train = X_train.loc[train_mask,'text'].to_list()\n","    y_train = Y_train.loc[train_mask, task].to_list()\n","\n","    val_mask = Y_train.kfold!=K\n","    x_val = X_train.loc[val_mask,'text'].to_list()\n","    y_val = Y_train.loc[val_mask, task].to_list()\n","\n","    data_splits_list.append( (x_train, y_train, x_val, y_val) )\n","\n","  return data_splits_list\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uC8YRWOGYV3U"},"source":["### evaluatePredictions()"]},{"cell_type":"code","metadata":{"id":"GTVaa7fwYV3V"},"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","def evaluatePredictions(task, val_labels, pred_labels):\n","\n","  if task=='HTA':\n","\n","    # get the correspondig predicted and val (target) labels for each task\n","    pred_HS_labels, pred_TR_labels, pred_AG_labels = dataset_utils.getLabelsPerTask(pred_labels)\n","    val_HS_labels, val_TR_labels, val_AG_labels = dataset_utils.getLabelsPerTask(val_labels)\n","\n","    # compute the different metrics\n","    A_acc = accuracy_score(val_HS_labels, pred_HS_labels)\n","    B1_acc = accuracy_score(val_TR_labels, pred_TR_labels)\n","    B2_acc = accuracy_score(val_AG_labels, pred_AG_labels)\n","\n","    A_f1 = f1_score(val_HS_labels, pred_HS_labels, average=\"macro\")\n","    B1_f1 = f1_score(val_TR_labels, pred_TR_labels, average=\"macro\")\n","    B2_f1 = f1_score(val_AG_labels, pred_AG_labels, average=\"macro\")\n","\n","    F1_multi = (A_f1 + B1_f1 + B2_f1)/3\n","\n","    EMR = computeEMR(list(zip(val_HS_labels, val_TR_labels, val_AG_labels)),\n","                    list(zip(pred_HS_labels, pred_TR_labels, pred_AG_labels)))\n","\n","    results_dict = {'A_acc':A_acc,\n","                    'B1_acc':B1_acc,\n","                    'B2_acc':B2_acc,\n","                    'A1_f1':A_f1,\n","                    'B1_f1':B1_f1,\n","                    'B2_f1':B2_f1,\n","                    'F1_multi':F1_multi,\n","                    'EMR':EMR}\n","\n","    print('EMR = ', EMR)\n","    print('F1_multi = ', F1_multi)\n","    print()\n","\n","    return results_dict\n","\n","  if task=='HS':\n","\n","    # get the correspondig predicted and val (target) labels for each task\n","    pred_HS_labels = pred_labels\n","    val_HS_labels = val_labels\n","\n","    # compute the different metrics\n","    A_acc = accuracy_score(val_HS_labels, pred_HS_labels)\n","    A_f1 = f1_score(val_HS_labels, pred_HS_labels, average=\"macro\")\n","\n","    results_dict = {'A_acc':A_acc,\n","                    'A1_f1':A_f1}\n","\n","    print('Acc = ', A_acc)\n","    print('F1_macro = ', A_f1)\n","    print()\n","\n","    return results_dict\n","    \n","\n","def computeEMR(test_labels, pred_labels):\n","  total_instances = len(test_labels)\n","  exact_match_count= 0\n","  for gold, pred in zip(test_labels, pred_labels):\n","    #print(gold, pred)\n","    if gold == pred:\n","      exact_match_count += 1\n","\n","  return exact_match_count/total_instances"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ArhByYiYV3W"},"source":["### labels_utils"]},{"cell_type":"code","metadata":{"id":"gIcqyhHvYV3X"},"source":["#**************************     getLabelsPerTask()    **************************\n","def getLabelsPerTask(HTA_labels):\n","\n","    HS_labels = list()\n","    TR_labels = list()\n","    AG_labels = list()\n","\n","    for HTA_label in HTA_labels:\n","        HS_label, TR_label, AG_label = mapTo3DimsFormat(HTA_label)\n","\n","        HS_labels.append(HS_label)\n","        TR_labels.append(TR_label)\n","        AG_labels.append(AG_label)\n","\n","    HS_labels = np.array(HS_labels).reshape(-1,1)\n","    TR_labels = np.array(TR_labels).reshape(-1,1)\n","    AG_labels = np.array(AG_labels).reshape(-1,1)\n","\n","    return (HS_labels, TR_labels, AG_labels)\n","\n","#**************************     mapTo3DimsFormat()    ************************** \n","def mapTo3DimsFormat(AB_label):\n","  '''\n","  Maps label in five_classes_format to 3 dims labeling.\n","\n","    0 -> (0,0,0)  [HT = 0, TR = 0, AG = 0]\n","    1 -> (1,0,0)  [HT = 1, TR = 0, AG = 0]\n","    2 -> (1,0,1)  [HT = 1, TR = 0, AG = 1]\n","    3 -> (1,1,0)  [HT = 1, TR = 1, AG = 0]\n","    4 -> (1,1,1)  [HT = 1, TR = 1, AG = 1]\n","\n","  inpunt:\n","  label    - int, label in five_classes_format\n","\n","  output:\n","  (H,T,A)  - ints tuple, labeling in 3 dims format\n","\n","  '''\n","  if AB_label == 0:\n","    return(0,0,0)\n","\n","  elif AB_label == 1:\n","    return(1,0,0)\n","\n","  elif AB_label == 2:\n","    return(1,0,1)\n","\n","  elif AB_label == 3:\n","    return(1,1,0)\n","\n","  elif AB_label == 4:\n","    return(1,1,1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"58XCQRapYV3Z"},"source":["## HS - linear kernel"]},{"cell_type":"code","metadata":{"id":"x1udSULuYV3a"},"source":["X_test, Y_test = dataset_utils.importTestDataForSVM()\n","X_test = X_test['text'].to_list()\n","# Y_test = Y_test['HTA'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixHDHTQIYV3g","executionInfo":{"status":"ok","timestamp":1617925941345,"user_tz":300,"elapsed":310743,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"a7e536bc-4b7d-4110-ccd8-829383f068d5"},"source":["configurations_ids = ['GQZgqx', 'hwmIFg', 'tgCmGg', 'fwZpdd', 'wavzCG']\n","textmodels_ids = ['CgOJHi', 'bVkhBU', 'wxNaSh', 'WHTRQA', 'iTLnGg']\n","\n","merged_results = DataFrame()\n","for config_ID, tm_ID in zip(configurations_ids, textmodels_ids):\n","  print(f'config_ID: {config_ID},  tm_ID: {tm_ID}\\n')\n","\n","  merged_results = merged_results.append(evaluateTrainedModels(X_test, Y_test, 'HS', config_ID, tm_ID, 'SVC-HS', 7),\n","                        ignore_index=True)\n","\n","with open('./Results/SVC_HS_batch_1.df', 'wb') as file_handler:\n","  pickle.dump(merged_results, file_handler)                        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["config_ID: GQZgqx,  tm_ID: CgOJHi\n","\n","\n","Evaluating data-fold 0\n","Transforming the test messages\n","Acc =  0.689375\n","F1_macro =  0.6797771970920612\n","\n","\n","Evaluating data-fold 1\n","Transforming the test messages\n","Acc =  0.715\n","F1_macro =  0.6996240360055925\n","\n","\n","Evaluating data-fold 2\n","Transforming the test messages\n","Acc =  0.70875\n","F1_macro =  0.7031374422678771\n","\n","\n","Evaluating data-fold 3\n","Transforming the test messages\n","Acc =  0.711875\n","F1_macro =  0.6976542379439833\n","\n","\n","Evaluating data-fold 4\n","Transforming the test messages\n","Acc =  0.709375\n","F1_macro =  0.6941482419073639\n","\n","\n","Evaluating data-fold 5\n","Transforming the test messages\n","Acc =  0.725\n","F1_macro =  0.7116720400513747\n","\n","\n","Evaluating data-fold 6\n","Transforming the test messages\n","Acc =  0.70875\n","F1_macro =  0.6988569812997294\n","\n","\n","Evaluating full-dataset model\n","Transforming the test messages\n","Acc =  0.7225\n","F1_macro =  0.7207683273299572\n","\n","\n","Evaluating MAJORITY VOTING ENSEMBLE\n","Acc =  0.753125\n","F1_macro =  0.7401904420503413\n","\n","config_ID: hwmIFg,  tm_ID: bVkhBU\n","\n","\n","Evaluating data-fold 0\n","Transforming the test messages\n","Acc =  0.6875\n","F1_macro =  0.677334004478604\n","\n","\n","Evaluating data-fold 1\n","Transforming the test messages\n","Acc =  0.716875\n","F1_macro =  0.7025606133292077\n","\n","\n","Evaluating data-fold 2\n","Transforming the test messages\n","Acc =  0.7075\n","F1_macro =  0.7018633540372671\n","\n","\n","Evaluating data-fold 3\n","Transforming the test messages\n","Acc =  0.706875\n","F1_macro =  0.69275505445368\n","\n","\n","Evaluating data-fold 4\n","Transforming the test messages\n","Acc =  0.70625\n","F1_macro =  0.6916637691808096\n","\n","\n","Evaluating data-fold 5\n","Transforming the test messages\n","Acc =  0.72625\n","F1_macro =  0.7137774031180619\n","\n","\n","Evaluating data-fold 6\n","Transforming the test messages\n","Acc =  0.709375\n","F1_macro =  0.6995734670069884\n","\n","\n","Evaluating full-dataset model\n","Transforming the test messages\n","Acc =  0.725625\n","F1_macro =  0.7237733100679988\n","\n","\n","Evaluating MAJORITY VOTING ENSEMBLE\n","Acc =  0.750625\n","F1_macro =  0.7378655008579731\n","\n","config_ID: tgCmGg,  tm_ID: wxNaSh\n","\n","\n","Evaluating data-fold 0\n","Transforming the test messages\n","Acc =  0.678125\n","F1_macro =  0.6683270440251573\n","\n","\n","Evaluating data-fold 1\n","Transforming the test messages\n","Acc =  0.725\n","F1_macro =  0.7108454320971428\n","\n","\n","Evaluating data-fold 2\n","Transforming the test messages\n","Acc =  0.710625\n","F1_macro =  0.7047870485678704\n","\n","\n","Evaluating data-fold 3\n","Transforming the test messages\n","Acc =  0.7075\n","F1_macro =  0.6951532294704753\n","\n","\n","Evaluating data-fold 4\n","Transforming the test messages\n","Acc =  0.70125\n","F1_macro =  0.6888020833333333\n","\n","\n","Evaluating data-fold 5\n","Transforming the test messages\n","Acc =  0.71875\n","F1_macro =  0.7052847358778176\n","\n","\n","Evaluating data-fold 6\n","Transforming the test messages\n","Acc =  0.705\n","F1_macro =  0.6931832401344924\n","\n","\n","Evaluating full-dataset model\n","Transforming the test messages\n","Acc =  0.724375\n","F1_macro =  0.7224572446093338\n","\n","\n","Evaluating MAJORITY VOTING ENSEMBLE\n","Acc =  0.7475\n","F1_macro =  0.7351127983464221\n","\n","config_ID: fwZpdd,  tm_ID: WHTRQA\n","\n","\n","Evaluating data-fold 0\n","Transforming the test messages\n","Acc =  0.681875\n","F1_macro =  0.6724791167231503\n","\n","\n","Evaluating data-fold 1\n","Transforming the test messages\n","Acc =  0.715\n","F1_macro =  0.7003307205370389\n","\n","\n","Evaluating data-fold 2\n","Transforming the test messages\n","Acc =  0.701875\n","F1_macro =  0.696598540476784\n","\n","\n","Evaluating data-fold 3\n","Transforming the test messages\n","Acc =  0.71\n","F1_macro =  0.6964537754379423\n","\n","\n","Evaluating data-fold 4\n","Transforming the test messages\n","Acc =  0.70625\n","F1_macro =  0.6936893488617626\n","\n","\n","Evaluating data-fold 5\n","Transforming the test messages\n","Acc =  0.718125\n","F1_macro =  0.7058381106784108\n","\n","\n","Evaluating data-fold 6\n","Transforming the test messages\n","Acc =  0.70125\n","F1_macro =  0.6900612096690528\n","\n","\n","Evaluating full-dataset model\n","Transforming the test messages\n","Acc =  0.72\n","F1_macro =  0.7184160905091137\n","\n","\n","Evaluating MAJORITY VOTING ENSEMBLE\n","Acc =  0.744375\n","F1_macro =  0.733089589963777\n","\n","config_ID: wavzCG,  tm_ID: iTLnGg\n","\n","\n","Evaluating data-fold 0\n","Transforming the test messages\n","Acc =  0.681875\n","F1_macro =  0.6724791167231503\n","\n","\n","Evaluating data-fold 1\n","Transforming the test messages\n","Acc =  0.723125\n","F1_macro =  0.7089584382959451\n","\n","\n","Evaluating data-fold 2\n","Transforming the test messages\n","Acc =  0.71\n","F1_macro =  0.7045145903881271\n","\n","\n","Evaluating data-fold 3\n","Transforming the test messages\n","Acc =  0.7075\n","F1_macro =  0.6951532294704753\n","\n","\n","Evaluating data-fold 4\n","Transforming the test messages\n","Acc =  0.69875\n","F1_macro =  0.686033881634122\n","\n","\n","Evaluating data-fold 5\n","Transforming the test messages\n","Acc =  0.720625\n","F1_macro =  0.7074941136871242\n","\n","\n","Evaluating data-fold 6\n","Transforming the test messages\n","Acc =  0.704375\n","F1_macro =  0.692611506516368\n","\n","\n","Evaluating full-dataset model\n","Transforming the test messages\n","Acc =  0.725\n","F1_macro =  0.7232286634460546\n","\n","\n","Evaluating MAJORITY VOTING ENSEMBLE\n","Acc =  0.745\n","F1_macro =  0.7333816905757289\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kGVgSPasYV3i"},"source":["## HS - sigmoid kernel"]},{"cell_type":"code","metadata":{"id":"gwKNcScnYV3j"},"source":["X_test, Y_test = dataset_utils.importTestDataForSVM()\n","X_test = X_test['text'].to_list()\n","# Y_test = Y_test['HTA'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ii7Az_uTYV3l"},"source":["configurations_ids = ['bKgjxA', 'ddJgKe', 'qnVrDo', 'ZSDGIu', 'eJPzqU']\n","textmodels_ids = ['fabKkA', 'pRduGU', 'SoAVcr', 'bcYlZN', 'Nilquo']\n","\n","merged_results = DataFrame()\n","for config_ID, tm_ID in zip(configurations_ids, textmodels_ids):\n","  print(f'config_ID: {config_ID},  tm_ID: {tm_ID}\\n')\n","\n","  merged_results = merged_results.append(evaluateTrainedModels(X_test, Y_test, 'HS', config_ID, tm_ID, 'SVC-HS', 7),\n","                        ignore_index=True)\n","\n","with open('./Results/SVC_HS_batch_2.df', 'wb') as file_handler:\n","  pickle.dump(merged_results, file_handler)    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Prr_uUVYV3m"},"source":["## HTA - linear kernel"]},{"cell_type":"code","metadata":{"id":"XKxKdR8kYV3n"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVnMljhLYV3o"},"source":["configurations_ids = ['eKpEEc', 'lFupON', 'XulowM', 'JonAxF', 'Etgzct']\n","textmodels_ids = ['wKlLLQ', 'pTurDN', 'HsOAlr', 'CmFmfJ', 'YXTXdt']\n","\n","from pandas import DataFrame\n","merged_results = DataFrame()\n","for config_ID, tm_ID in zip(configurations_ids, textmodels_ids):\n","  print(f'config_ID: {config_ID},  tm_ID: {tm_ID}\\n')\n","\n","  merged_results = merged_results.append(evaluateTrainedModelsOnValidationData(X_train, Y_train, \n","                                                                               'HTA', \n","                                                                               config_ID, \n","                                                                               tm_ID, \n","                                                                               'SVC-LINEAR', 7),\n","                        ignore_index=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K0s-NEUMYV3p"},"source":["with open('./Results/final/SVC-LINEAR_HTA_VALIDATION.df', 'wb') as file_handler:\n","  pickle.dump(merged_results, file_handler) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"id":"t8n7btWFlir8","executionInfo":{"status":"ok","timestamp":1618558206535,"user_tz":300,"elapsed":560,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"7332eac7-fed2-4760-8a29-df1a4085c53d"},"source":["merged_results.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>conf_id</th>\n","      <th>tm_ID</th>\n","      <th>model_type</th>\n","      <th>architecture</th>\n","      <th>A_acc</th>\n","      <th>B1_acc</th>\n","      <th>B2_acc</th>\n","      <th>A1_f1</th>\n","      <th>B1_f1</th>\n","      <th>B2_f1</th>\n","      <th>F1_multi</th>\n","      <th>EMR</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>KAcOYq</td>\n","      <td>djwYeF</td>\n","      <td>F</td>\n","      <td>SVC-LINEAR</td>\n","      <td>0.764527</td>\n","      <td>0.878413</td>\n","      <td>0.791599</td>\n","      <td>0.738408</td>\n","      <td>0.823373</td>\n","      <td>0.750901</td>\n","      <td>0.770894</td>\n","      <td>0.733256</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>KAcOYq</td>\n","      <td>djwYeF</td>\n","      <td>F</td>\n","      <td>SVC-LINEAR</td>\n","      <td>0.755193</td>\n","      <td>0.886348</td>\n","      <td>0.801867</td>\n","      <td>0.726217</td>\n","      <td>0.840688</td>\n","      <td>0.759528</td>\n","      <td>0.775478</td>\n","      <td>0.733489</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>KAcOYq</td>\n","      <td>djwYeF</td>\n","      <td>F</td>\n","      <td>SVC-LINEAR</td>\n","      <td>0.765049</td>\n","      <td>0.878208</td>\n","      <td>0.797247</td>\n","      <td>0.741764</td>\n","      <td>0.829786</td>\n","      <td>0.760284</td>\n","      <td>0.777278</td>\n","      <td>0.736118</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>KAcOYq</td>\n","      <td>djwYeF</td>\n","      <td>F</td>\n","      <td>SVC-LINEAR</td>\n","      <td>0.764349</td>\n","      <td>0.884974</td>\n","      <td>0.800513</td>\n","      <td>0.736022</td>\n","      <td>0.836543</td>\n","      <td>0.759775</td>\n","      <td>0.777447</td>\n","      <td>0.737517</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>KAcOYq</td>\n","      <td>djwYeF</td>\n","      <td>F</td>\n","      <td>SVC-LINEAR</td>\n","      <td>0.758049</td>\n","      <td>0.872842</td>\n","      <td>0.793047</td>\n","      <td>0.728733</td>\n","      <td>0.817040</td>\n","      <td>0.749146</td>\n","      <td>0.764973</td>\n","      <td>0.731685</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  conf_id   tm_ID model_type  ...     B2_f1  F1_multi       EMR\n","0  KAcOYq  djwYeF          F  ...  0.750901  0.770894  0.733256\n","1  KAcOYq  djwYeF          F  ...  0.759528  0.775478  0.733489\n","2  KAcOYq  djwYeF          F  ...  0.760284  0.777278  0.736118\n","3  KAcOYq  djwYeF          F  ...  0.759775  0.777447  0.737517\n","4  KAcOYq  djwYeF          F  ...  0.749146  0.764973  0.731685\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"k7-mnADDYV3q"},"source":["## HTA - sigmoid kernel"]},{"cell_type":"code","metadata":{"id":"60ygRA7FYV3q"},"source":["X_train, Y_train = dataset_utils.importTrainDataForSVM()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4kF-zyKYV3r"},"source":["configurations_ids = ['KAcOYq', 'bmCbAB', 'pcPfNL', 'wNOXbH', 'hVEaUj']\n","textmodels_ids = ['djwYeF', 'TqHwoB', 'sUlSKy', 'CgdcXu', 'oDWZfJ']\n","\n","from pandas import DataFrame\n","merged_results = DataFrame()\n","for config_ID, tm_ID in zip(configurations_ids, textmodels_ids):\n","  print(f'config_ID: {config_ID},  tm_ID: {tm_ID}\\n')\n","\n","  merged_results = merged_results.append(evaluateTrainedModelsOnValidationData(X_train, Y_train, \n","                                                                               'HTA', \n","                                                                               config_ID, \n","                                                                               tm_ID, \n","                                                                               'SVC-SIGMOID', 7),\n","                        ignore_index=True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMATpa1Fjo65"},"source":["with open('./Results/final/SVC-SIGMOID_HTA_VALIDATION.df', 'wb') as file_handler:\n","  pickle.dump(merged_results, file_handler) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P-k6HA_HvaP9"},"source":["with open('./Results/final/SVC-SIGMOID_HTA_VALIDATION.df', 'rb') as file_handler:\n","  merged_results = pickle.load(file_handler) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIlnHYevYV3t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622872658650,"user_tz":300,"elapsed":221,"user":{"displayName":"Felipe Ramírez Brindis","photoUrl":"","userId":"16823923198286569615"}},"outputId":"fc27c5f0-a088-4795-c089-42877556d40f"},"source":["merged_results.loc[merged_results.conf_id=='KAcOYq'].mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["A_acc       0.763633\n","B1_acc      0.881700\n","B2_acc      0.798767\n","A1_f1       0.737089\n","B1_f1       0.831993\n","B2_f1       0.758838\n","F1_multi    0.775973\n","EMR         0.736766\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":11}]}]}